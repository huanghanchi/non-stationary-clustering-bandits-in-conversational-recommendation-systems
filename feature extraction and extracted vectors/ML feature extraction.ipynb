{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "# read flash.dat to a list of lists\n",
    "datContent = [i.strip().split() for i in open(r'user_taggedmovies-timestamps.dat').readlines()]\n",
    "df=pd.DataFrame(datContent[1:],columns=datContent[0])\n",
    "df.to_csv(r'user_taggedmovies-timestamps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(datContent[1:],columns=datContent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movies.dat',\n",
       " 'movie_actors.dat',\n",
       " 'movie_countries.dat',\n",
       " 'movie_directors.dat',\n",
       " 'movie_genres.dat',\n",
       " 'movie_locations.dat',\n",
       " 'movie_tags.dat',\n",
       " 'tags.dat',\n",
       " 'user_ratedmovies-timestamps.dat',\n",
       " 'user_ratedmovies.dat',\n",
       " 'user_taggedmovies-timestamps.dat',\n",
       " 'user_taggedmovies.dat']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def walkFile(file):\n",
    "    filelist=[]\n",
    "    for root, dirs, files in os.walk(file):\n",
    "\n",
    "        for f in files:\n",
    "            filelist.append(os.path.join(f))\n",
    "\n",
    "        return filelist\n",
    "filelist=walkFile(r\"hetrec2011-movielens-2k\")\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to csv\n",
    "datContent = [i.strip().split('\t') for i in open(r'movies.dat','r', encoding='mac_roman').readlines()]\n",
    "df=pd.DataFrame(datContent[1:],columns=datContent[0])\n",
    "df.to_csv(r'movies.csv')\n",
    "print(r'movies.csv')\n",
    "for i in filelist[2:]:\n",
    "    datContent = [i.strip().split('\t') for i in open(r''+i, encoding='mac_roman').readlines()]\n",
    "    df=pd.DataFrame(datContent[1:],columns=datContent[0])\n",
    "    i=i.strip('.dat')+'.csv'\n",
    "    df.to_csv(r''+i)\n",
    "    print(r''+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv(r'movies.csv')\n",
    "movies.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "tags=pd.read_csv(r'gs.csv')\n",
    "tags.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "user_taggedmovies_timestamps=pd.read_csv(r'user_taggedmovies-timestamps.csv')\n",
    "user_taggedmovies_timestamps.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "user_taggedmovies_timestamps=user_taggedmovies_timestamps.sort_values(by=['timestamp'])\n",
    "user_taggedmovies=pd.read_csv(r'user_taggedmovies.csv')\n",
    "user_taggedmovies.drop(['Unnamed: 0'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 most frequent users\n",
    "frequentUser=np.array(user_taggedmovies.userID.value_counts().index[:5000])\n",
    "#10 most frequent items\n",
    "frequentItem=list(user_taggedmovies.movieID.value_counts().index[:10000])\n",
    "frequentUserData=user_taggedmovies_timestamps[(user_taggedmovies_timestamps['userID'].isin(frequentUser))].sort_values(by=['timestamp'])\n",
    "freqData=user_taggedmovies_timestamps[(user_taggedmovies_timestamps['userID'].isin(frequentUser))&(user_taggedmovies_timestamps['movieID'].isin(frequentItem))].sort_values(by=['timestamp'])\n",
    "userFlow=list(freqData.userID)\n",
    "trueResultFlow=list(freqData.movieID)\n",
    "len(userFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba  \n",
    "import jieba.posseg as pseg  \n",
    "import os  \n",
    "import sys \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "corpus=list(tags.value)\n",
    "vectorizer=CountVectorizer()\n",
    "transformer=TfidfTransformer()  \n",
    "tfidf=transformer.fit_transform(vectorizer.fit_transform(corpus)) \n",
    "word=vectorizer.get_feature_names()\n",
    "weight=tfidf.toarray()\n",
    "print( 'Start Kmeans:')\n",
    "\n",
    "clf = KMeans(n_clusters=4)   \n",
    "s = clf.fit(weight)\n",
    "label = []     \n",
    "i = 1\n",
    "while i <= len(clf.labels_):\n",
    "    #print( clf.labels_[i-1])\n",
    "    label.append(clf.labels_[i-1])\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "newData = pca.fit_transform(weight)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'newData.npy',newData)\n",
    "newData=np.load(r'newData.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataDict={}\n",
    "for i in range(len(newData)):\n",
    "    newDataDict[tags.id[i]]=newData[i]\n",
    "\n",
    "frequentItemDict={}\n",
    "for i in frequentItem:\n",
    "    temp=np.zeros(10)\n",
    "    for j in list(user_taggedmovies_timestamps[user_taggedmovies_timestamps.movieID==i].tagID):\n",
    "        if j<len(newData):\n",
    "            temp+=newDataDict[j]\n",
    "    if np.linalg.norm(temp, ord=2)==0.:\n",
    "        print(i)\n",
    "        frequentItemDict[i]=temp\n",
    "    else:\n",
    "        frequentItemDict[i]=temp/np.linalg.norm(temp, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KMeans(n_clusters=40)\n",
    "s1 = clf1.fit(list(frequentItemDict.values()))\n",
    "\n",
    "frequentItemCluster={}\n",
    "for i in range(len(frequentItem)):\n",
    "    frequentItemCluster[frequentItem[i]]=clf1.labels_[i]\n",
    "frequentItemVec={}\n",
    "for i in range(40):\n",
    "    frequentItemVec[i]=np.zeros(10)\n",
    "for i in frequentItem:\n",
    "    frequentItemVec[frequentItemCluster[i]]+=frequentItemDict[i]\n",
    "for i in range(40):\n",
    "    frequentItemVec[i]=frequentItemVec[i]/np.linalg.norm(frequentItemVec[i], ord=2)\n",
    "\n",
    "stage1Data=user_taggedmovies_timestamps\n",
    "#stage2Data=user_taggedmovies_timestamps[50000:100000]\n",
    "#stage3Data=user_taggedmovies_timestamps[100000:150000]\n",
    "#stage4Data=user_taggedmovies_timestamps[150000:]\n",
    "frequentUserDict1={}\n",
    "#frequentUserDict2={}\n",
    "#frequentUserDict3={}\n",
    "#frequentUserDict4={}\n",
    "for i in frequentUser:\n",
    "    temp=np.zeros(10)\n",
    "    for j in list(stage1Data[stage1Data.userID==i].tagID):\n",
    "        if j<len(newData):\n",
    "            temp+=newDataDict[j]\n",
    "    if np.linalg.norm(temp, ord=2)==0:\n",
    "        frequentUserDict1[i]=np.ones(10)/np.linalg.norm(np.ones(10), ord=2)\n",
    "    else:\n",
    "        frequentUserDict1[i]=temp/np.linalg.norm(temp, ord=2)\n",
    "        \n",
    "\"\"\"\n",
    "for i in frequentUser:\n",
    "    temp=np.zeros(10)\n",
    "    for j in list(stage2Data[stage2Data.userID==i].id):\n",
    "        temp+=newDataDict[j]\n",
    "    if np.linalg.norm(temp, ord=2)==0:\n",
    "        frequentUserDict2[i]=np.ones(10)/np.linalg.norm(np.ones(10), ord=2)\n",
    "    else:\n",
    "        frequentUserDict2[i]=temp/np.linalg.norm(temp, ord=2)\n",
    "for i in frequentUser:\n",
    "    temp=np.zeros(10)\n",
    "    for j in list(stage3Data[stage3Data.userID==i].id):\n",
    "        temp+=newDataDict[j]\n",
    "    if np.linalg.norm(temp, ord=2)==0:\n",
    "        frequentUserDict3[i]=np.ones(10)/np.linalg.norm(np.ones(10), ord=2)\n",
    "    else:\n",
    "        frequentUserDict3[i]=temp/np.linalg.norm(temp, ord=2)\n",
    "for i in frequentUser:\n",
    "    temp=np.zeros(10)\n",
    "    for j in list(stage4Data[stage4Data.userID==i].id):\n",
    "        temp+=newDataDict[j]\n",
    "    if np.linalg.norm(temp, ord=2)==0:\n",
    "        frequentUserDict4[i]=np.ones(10)/np.linalg.norm(np.ones(10), ord=2)\n",
    "    else:\n",
    "        frequentUserDict4[i]=temp/np.linalg.norm(temp, ord=2)\n",
    "\n",
    "freqUserFeatureDict={}\n",
    "for i in frequentUser:\n",
    "    freqUserFeatureDict[i]=[]\n",
    "    for j in range(len(freqData)//4):\n",
    "        freqUserFeatureDict[i].append(frequentUserDict1[i])\n",
    "    for j in range(len(freqData)//4):\n",
    "        freqUserFeatureDict[i].append(frequentUserDict2[i])\n",
    "    for j in range(len(freqData)//4):\n",
    "        freqUserFeatureDict[i].append(frequentUserDict3[i])\n",
    "    for j in range(len(freqData)-3*len(freqData)//4):\n",
    "        freqUserFeatureDict[i].append(frequentUserDict4[i])\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'frequentUserDict300_del.npy',frequentUserDict1)\n",
    "np.save(r'frequentItemVec.npy',frequentItemVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexflow=[]\n",
    "for i in range(len(user_taggedmovies_timestamps)):\n",
    "    if i%500==0:\n",
    "        print(i)\n",
    "    if user_taggedmovies_timestamps.iloc[i].movieID in list(frequentItemDict.keys()):\n",
    "        indexflow.append(i)\n",
    "movieflow=user_taggedmovies_timestamps.iloc[indexflow].movieID.values\n",
    "userflow=user_taggedmovies_timestamps.iloc[indexflow].userID.values\n",
    "movieflow=[frequentItemCluster[i] for i in movieflow]\n",
    "np.save(r'userflow.npy',userflow)\n",
    "np.save(r'movieflow.npy',movieflow)\n",
    "np.save(r'frequentItemVec.npy',np.array(list(frequentItemVec.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'userflow.npy',userflow)\n",
    "np.save(r'movieflow.npy',movieflow)\n",
    "np.save(r'frequentItemVec.npy',np.array(list(frequentItemVec.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userflowdict={}\n",
    "userflowlist=list(set(userflow))\n",
    "for i in range(len(set(userflow))):\n",
    "    userflowdict[userflowlist[i]]=i\n",
    "userclick=[[] for i in range(len(set(userflow)))]\n",
    "for i in range(len(userflow)):\n",
    "    userclick[userflowdict[userflow[i]]].append(movieflow[i])\n",
    "userflowRenew=[]\n",
    "for i in userflow:\n",
    "    userflowRenew.append(userflowdict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'userclick.npy',userclick)\n",
    "np.save(r'userflow.npy',userflowRenew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
